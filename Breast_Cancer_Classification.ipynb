{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from the csv file\n",
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "# data.drop('Unnamed: 32', axis=1, inplace=True)\n",
    "data.loc[data['diagnosis'] == 'M', 'diagnosis'] = 1\n",
    "data.loc[data['diagnosis'] == 'B', 'diagnosis'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "564  926424          1        21.56         22.39          142.00     1479.0   \n",
       "565  926682          1        20.13         28.25          131.20     1261.0   \n",
       "566  926954          1        16.60         28.08          108.30      858.1   \n",
       "567  927241          1        20.60         29.33          140.10     1265.0   \n",
       "568   92751          0         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_data is: (569, 30)\n",
      "Shape of Y_data is: (569,)\n"
     ]
    }
   ],
   "source": [
    "#Define X and Y values. Y specifies whether person will have a heardisease or not(0=NO, 1=Yes) and X is rest of the columns.\n",
    "X_data = data.loc[:, 'radius_mean':'fractal_dimension_worst']\n",
    "Y_data = data.loc[:, 'diagnosis']\n",
    "print(\"Shape of X_data is: \" + str(X_data.shape))\n",
    "print(\"Shape of Y_data is: \" + str(Y_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_train is: (455, 1)\n",
      "Shape of Y_test is: (114, 1)\n"
     ]
    }
   ],
   "source": [
    "#Split dataset into 80%train and 20% test set and reshape Y_train and Y_test.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2)\n",
    "Y_train = Y_train.values.reshape(Y_train.shape[0], 1)\n",
    "Y_test = Y_test.values.reshape(Y_test.shape[0], 1)\n",
    "print(\"Shape of Y_train is: \" + str(Y_train.shape))\n",
    "print(\"Shape of Y_test is: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 455\n",
      "Number of test samples: 114\n",
      "Number of features: 30\n"
     ]
    }
   ],
   "source": [
    "#assign number of train, test and input features to variables\n",
    "m_train = X_train.shape[0]\n",
    "m_test = X_test.shape[0]\n",
    "num_features = X_train.shape[1]\n",
    "print(\"Number of training samples: \" + str(m_train))\n",
    "print(\"Number of test samples: \" + str(m_test))\n",
    "print(\"Number of features: \" + str(num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Transpose of X_train: (30, 455)\n",
      "Shape of Transpose of X_test: (30, 114)\n"
     ]
    }
   ],
   "source": [
    "#Taking the transpose to make life easier and converting Y values to one_hot format --> [0 1] = [[1 0]\n",
    "#                                                                                               [0 1]]    \n",
    "X_train=X_train.T\n",
    "X_test=X_test.T\n",
    "Y_train = convert_to_one_hot(Y_train, 2)\n",
    "Y_test = convert_to_one_hot(Y_test, 2)\n",
    "print(\"Shape of Transpose of X_train: \" + str(X_train.shape))\n",
    "print(\"Shape of Transpose of X_test: \" + str(X_test.shape))\n",
    "# print(\"Hot values of Y_train: \" + str(Y_train))\n",
    "# print(\"Hot values of Y_test: \" + str(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Placeholders with number of features and number of output values fixed and number of training examples varying.\n",
    "def create_placeholders(n_x, n_y):\n",
    "    X = tf.placeholder(tf.float32, shape=[n_x, None], name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32, shape=[n_y, None], name=\"Y\")\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X_1:0\", shape=(30, ?), dtype=float32)\n",
      "Y = Tensor(\"Y_1:0\", shape=(2, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#call placeholder method with x and y dimension values\n",
    "X, Y = create_placeholders(30, 2)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the parameters. The following are the dimensions I used for the parameters:\n",
    "#                        W1 : [25, 30]\n",
    "#                        b1 : [25, 1]\n",
    "#                        W2 : [12, 25]\n",
    "#                        b2 : [12, 1]\n",
    "#                        W3 : [1, 12]\n",
    "#                        b3 : [1, 1]\n",
    "\n",
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1) \n",
    "    W1 = tf.get_variable(\"W1\", [25,30], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [12, 25], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable(\"b2\", [12, 1], initializer=tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [2,12], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b3 = tf.get_variable(\"b3\", [2, 1], initializer=tf.zeros_initializer())\n",
    "    \n",
    "    #Creating parmeters dictionary\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(25, 30) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref>\n",
      "W3 = <tf.Variable 'W3:0' shape=(2, 12) dtype=float32_ref>\n",
      "b3 = <tf.Variable 'b3:0' shape=(2, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "#Call initialize parameters to check values of W1, b1, W2, b2\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "    print(\"W3 = \" + str(parameters[\"W3\"]))\n",
    "    print(\"b3 = \" + str(parameters[\"b3\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward Propagation\n",
    "def forward_propagation(X, parameters):\n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                                # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                               # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                               # Z3 = np.dot(W3,Z2) + b3\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the function forward_propagation\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(30, 2)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute cost\n",
    "def compute_cost(Z3, Y):\n",
    "# def compute_cost(Z2, Y):\n",
    "\n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Calling compute cost function\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(30, 2)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model. Call all the helper function created.\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001, num_epochs = 1500, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    #Create Placeholders\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    #Initialize Parameters\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    #Forward Propogation\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "\n",
    "    #Compute cost\n",
    "    cost = compute_cost(Z3, Y)\n",
    "\n",
    "    #Backpropagation: Due to tensorflow no need to compute each step. \n",
    "    #Just define the tensorflow optimizer. I am using an AdamOptimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    #Starting the session\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Running the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Loop for number of epochs defined\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            _, train_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n",
    "            epoch_cost = train_cost\n",
    "\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.971543\n",
      "Cost after epoch 100: 0.419691\n",
      "Cost after epoch 200: 0.381097\n",
      "Cost after epoch 300: 0.346045\n",
      "Cost after epoch 400: 0.317676\n",
      "Cost after epoch 500: 0.294794\n",
      "Cost after epoch 600: 0.276553\n",
      "Cost after epoch 700: 0.262439\n",
      "Cost after epoch 800: 0.251706\n",
      "Cost after epoch 900: 0.243395\n",
      "Cost after epoch 1000: 0.236597\n",
      "Cost after epoch 1100: 0.230626\n",
      "Cost after epoch 1200: 0.225043\n",
      "Cost after epoch 1300: 0.219618\n",
      "Cost after epoch 1400: 0.214253\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "('Train Accuracy:', 0.9252747)\n",
      "('Test Accuracy:', 0.9385965)\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
